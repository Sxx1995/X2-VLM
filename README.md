# X$^2$-VLM: All-In-One Pre-trained Model For Vision-Language Tasks

All-In-One == Image + Video + Transfer to Other Languages / Domains

- Jan 2023: We will release codes and pre-trained models in Jan 2023. 
- Nov 2022: Release preprint in arxiv. 

